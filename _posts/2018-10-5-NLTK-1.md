---
layout: post
title: "NLTK学习笔记_1"
description: "自然语言处理库NLTK"
categories: [笔记]
tags: [计算机,自然语言处理,Python]
redirect_from:
  -/2018/10/05/
---

# NLTK学习笔记_1

* Kramdown table of contents
{:toc .toc}

## 自然语言处理与 NLTK

自然语言处理（NLP）[^1]是人工智能与语言学领域的分支学科，探讨如何处理与运用自然语言，包括认知，理解，生成等部分。

NLTK（Natural Language Toolkit）[^2]是一套用 Python 语言编写的用于自然语言统计处理的库与程序，以下的所有内容将基于 NLTK 3.3 与 Python 3.6

NLTK 中主要的模块与其对应的功能：

|Language processing task|NLTK modules|Functionality|
|:-|:-|:-|
|Accessing corpora|corpus|standardized interfaces to corpora and lexicons|
|String processing|tokenize, stem|tokenizers, sentence tokenizers, stemmers|
|Collocation discovery|collocations|t-test, chi-squared, point-wise mutual information|
|Part-of-speech tagging|tag|n-gram, backoff, Brill, HMM, TnT|
|Machine learning|classify, cluster, tbl|decision tree, maximum entropy, naive Bayes, EM, k-means|
|Chunking|chunk|regular expression, n-gram, named-entity|
|Parsing|parse, ccg|chart, feature-based, unification, probabilistic, dependency|
|Semantic interpretation|sem, inference|lambda calculus, first-order logic, model checking|
|Evaluation metrics|metrics|precision, recall, agreement coefficients|
|Probability and estimation|probability|frequency distributions, smoothed probability distributions|
|Applications|app, chat|graphical concordancer, parsers, WordNet browser, chatbots|
|Linguistic fieldwork|toolbox|manipulate data in SIL Toolbox format|

## Text

Text 类是 NLTK 提供的一个用于简单的文本分析的类，包含了一系列对于文本的处理方法.（如果想编写分析文本的程序，不建议使用 Text，而应当使用对应的函数或类）。Text 位于 [nltk.text.Text][text]，可使用一个字符串的序列构造一个 Text 对象。E.g.:

```python
>>> import nltk.corpus
>>> from nltk.text import Text
>>> moby = Text(nltk.corpus.gutenberg.words('melville-moby_dick.txt'))
```

Text 类中有以下几个重要的方法

### Text.concordance

[concordance(word, width=79, lines=25)][concordance] 可以检索 text 中的 word 以及其出现的上下文，对单词的大小写不敏感。

* word(str):目标单词
* width(int):输出结果每行的宽度，单位是字符数
* lines(int):输出结果的行数

### Text.similar

[similar(word, num=20)][similar] 可以检索 text 中与 word 有相似上下文的单词，输出结果按相似程度匹配

* word(str):目标单词
* num(int):结果的数量

### Text.common_contexts

[common_contexts(words, num=20)][common_contexts] 可以输出 text 中多个目标单词共同的上下文，接受一个单词序列作为参数

* words(str):目标单词序列（一个或多个）
* num(int):结果的数量

### Text.collocations

[collocations(num=20, window_size=2)][collocations] 返回 text 中出现最频繁的二元词组。

* num(int):输出的结果的数量
* window_size(int):搭配中跨越的字符的数量

可使用 [nltk.util.bigrams][bigrams] 来生成二元词组，其接受一个序列或迭代器作为参数，返回一个元祖的迭代器，可使用`list()`方法将其转化为列表

### Text 类的其余方法

|方法|功能|
|:-|:-|
|[count(word)][count]|返回 text 中 word 的数量|
|[index(word)][index]|返回 text 中 word 首次出现的下标|
|[dispersion_plot(words)][dispersion_plot]|根据 words 在 text 中出现的位置绘制图表|
|[plot(*args)][plot]|根据参数绘制图表|

## 频率分布

频率分布（Frequency distribution）[^3]是列表，表格或图表，显示样本中各种结果的频率。表中的每个条目都包含特定组或区间内值的出现频率或计数。在 NLTK 中，提供了频率分布类 FreqDist，位于[nltk.probability.FreqDist][freqdist]，构造参数为需要统计频率分布的样本。E.g.:

```python
>>> from nltk.tokenize import word_tokenize
>>> from nltk.probability import FreqDist
>>> sent = 'This is an example sentence'
>>> fdist = FreqDist()
>>> for word in word_tokenize(sent):
...    fdist[word.lower()] += 1
```

以下语句可以达到同样的效果

```python
>>> fdist = FreqDist(word.lower() for word in word_tokenize(sent))
```

FreqDist 类中有以下几个重要方法

### FreqDist.plot

[plot(\*args, \*\*kwargs)][fd_plot] 可以绘出频率分布的图表，**需要 Matplotlib 库**

* \*args(int):一个整型数，表示参与绘图的 FreqDist 中样本的个数（按出现次数由多到少排列，无此参数时默认为所有样本）
* \*\*kwargs:title(str):图表的标题，无此参数则无标题
* \*\*kwargs:cumulative(bool):是否为累积频率

### FreqDist.tabulate

[tabulate(\*args, \*\*kwargs)][tabulate] 以表格的形式展现样本的频率分布

* \*args(int):一个整型数，表示显示的样本的个数（按出现次数由多到少排列，无此参数时默认为所有样本）
* \*\*kwargs:cumulative(bool):是否为累积频率

### FreqDist 类的其余方法

|方法|功能|
|:-|:-|
|[B()][b]|返回样本中所有出现次数大于0的样本的个数（相当于len(freqdist)）|
|[N()][n]|返回所有样本出现次数的总和|
|[copy()][copy]|返回一个 FreqDist 的拷贝|
|[freq(sample)][freq]|返回一个样本出现的频率|
|[hapaxes()][hapaxes]|返回一个列表，包含所有只出现了1次的样本|
|[max()][max]|返回所有样本中出现次数最多的样本，**若有多个样本出现的次数相同，返回哪一个是未定义的**|
|[most_common()][most_common]|返回出现次数最频繁的词与频度|

## Reference

* [NLTK Book](http://www.nltk.org/book/)
* [nltk Package — NLTK 3.3 documentation](http://www.nltk.org/api/nltk.html)

[^1]:["自然语言处理 - 维基百科，自由的百科全书"](https://zh.wikipedia.org/wiki/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86)
[^2]:["Natural Language Toolkit — NLTK 3.3 documentation"](https://www.nltk.org/)
[^3]:["Frequency distribution - Wikipedia"](https://en.wikipedia.org/wiki/Frequency_distribution)

[text]:https://www.nltk.org/api/nltk.html#nltk.text.Text
[concordance]:https://www.nltk.org/api/nltk.html#nltk.text.Text.concordance
[similar]:https://www.nltk.org/api/nltk.html#nltk.text.Text.similar
[common_contexts]:https://www.nltk.org/api/nltk.html#nltk.text.Text.common_contexts
[collocations]:https://www.nltk.org/api/nltk.html#nltk.text.Text.collocations
[count]:https://www.nltk.org/api/nltk.html#nltk.text.Text.count
[index]:https://www.nltk.org/api/nltk.html#nltk.text.Text.index
[dispersion_plot]:https://www.nltk.org/api/nltk.html#nltk.text.Text.dispersion_plot
[plot]:https://www.nltk.org/api/nltk.html#nltk.text.Text.plot
[freqdist]:http://www.nltk.org/api/nltk.html?highlight=freqdist#nltk.probability.FreqDist
[fd_plot]:http://www.nltk.org/api/nltk.html?highlight=freqdist#nltk.probability.FreqDist.plot
[tabulate]:http://www.nltk.org/api/nltk.html?highlight=freqdist#nltk.probability.FreqDist.tabulate
[b]:http://www.nltk.org/api/nltk.html?highlight=freqdist#nltk.probability.FreqDist.B
[n]:http://www.nltk.org/api/nltk.html?highlight=freqdist#nltk.probability.FreqDist.N
[copy]:http://www.nltk.org/api/nltk.html?highlight=freqdist#nltk.probability.FreqDist.copy
[freq]:http://www.nltk.org/api/nltk.html?highlight=freqdist#nltk.probability.FreqDist.freq
[hapaxes]:http://www.nltk.org/api/nltk.html?highlight=freqdist#nltk.probability.FreqDist.hapaxes
[max]:http://www.nltk.org/api/nltk.html?highlight=freqdist#nltk.probability.FreqDist.max
[bigrams]:http://www.nltk.org/api/nltk.html?highlight=freqdist#nltk.util.bigrams
[most_common]:https://docs.python.org/dev/library/collections.html#collections.Counter.most_common